{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Filarh/Fooocus/blob/main/invocar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqY-GmKTL8V"
      },
      "source": [
        "# **StableDiffusion InvokeAI Base Cloud version**\n",
        "\n",
        "\n",
        "![youtube.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAJ1BMVEVHcEz/AAD/AAD/AAD/AAD/AAD/AAD/AAD/AAD/////mJj/wcH/jY3aUCqcAAAACHRSTlMA8czbELSvDrGIfzkAAABCSURBVBiVY2AgA7CwMTMycgABIyMzGztQgIkDCTABBThQAEyAixtNgIeTkwu/AIYWZEMxrGVhZWaE8BiZWVnI8RoAJWEEDt2WmW4AAAAASUVORK5CYII=) **[YouTube](https://www.youtube.com/@marat_ai)** | ![youtube.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAA0lBMVEVHcEwASXEAVIIASXEAW40AW40AW40AW40AW40AW40ASXEARmwASXEAPV4ATnkAQGQAUoAAUn8AWowAQmYANFEANVIAQWUASXEAUHwAQmcAWowASXEAUX0AW40ASXGPscSPr8B/pLh/rcYMUXdJfZkDS3KlwtIqdqBWhqB9q8WZtsY/dpQzbY1Xh6GUs8MAWowAUHwAVoUqdp8AVIJ9pLkqZ4h9orelvsyJq70AWosAWYoATniNrb+kwM8ATHZ+oreBpbnF1t8DS3PI1+BbiaNbiqT25ex8AAAAHXRSTlMAmzOe3PvEmp3+3Ar+CjM0M/v7CgoKCsUzNNz7+yV3I4EAAACzSURBVBjTTY/XEoJADEUjbUEBezdrASxg7737/79kdmEcz9PeM5NsLgCRY5qua0yBmKJpocQyMyJXDPxhCGPiHyZAzcJBvy3pL9FSgCGOhlwyXC+QgYbYO/si+/suXzVAJ+Hdyfg3r8t5Kxbj12TyGAvRlCPR9Pl5B9OIRFouDQOxIwi3nKfApW8vHcluw+26POx45QkqXerQ6YdTnKtlUcahcrM5RVstJX1dphXy6VRWvL8EBRlO0i9n9wAAAABJRU5ErkJggg==) **[sdg.marat@gmail.com]** |\n",
        "![pp.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAtUlEQVQ4jWNgYGBYCcSrgLibARNwAnEUEE8G4gVAXAvEOuiK/gHxfyC+gCbuAMSPoXLIGKR+NhBz4DPACoh/YNGMjDcAMSM2A5iB+DoBzTAcgc0AByI1g/BebAYUkWDAe2wGlJFgwBdsBviTYMBpbAZwAfFLIg0owGYACEQRofk8AzQt4EpI2UD8C4fmk0AsBVOIywAQUGaAJPEjQHwJiNcBcTQDJK3AAT4DiAIDbwC+7EwQAADZX5HHysvpxQAAAABJRU5ErkJggg==) [Other Notebooks](https://www.patreon.com/marat_ai)\n",
        "\n",
        "_You don't need additional Google Drive storage because uploaded models are not stored on your Google Drive. After the session ends, all data will be deleted._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "JQ5qVdNPFqYJ"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 1**\n",
        "#@markdown ## Requirements\n",
        "#@markdown It might finished with error but is not the error, just execute the next cell\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/rocketpal/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.22 triton==2.0.0 -U\n",
        "clear_output()\n",
        "\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/rocketpal/InvokeAI-colab/main/INITIAL_MODELS.yaml -O /content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!pip install python-socketio==5.9.0\n",
        "clear_output()\n",
        "\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "aBZ0AbI-U_zk",
        "outputId": "df9e3bc9-93d1-4851-a019-49cc9f10d3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 2**\n",
        "#@markdown ## Downloading models _(checkpoints, LoRAs, ControlNets, etc.)_\n",
        "#@markdown To configure the downloading of models, edit this file:\n",
        "#@markdown _/content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml_\n",
        "\n",
        "#@markdown P.S. It's fully explained in the tutorial.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --yes\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "AuFwU5t8POIS",
        "outputId": "bf42e4a9-e8c3-46d4-9a57-97dc882dba91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1;32m Model just loaded! ðŸš€\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### Load Model (option2)\n",
        "model_link = \"https://civitai.com/api/download/models/272376\" # @param {type:\"string\"}\n",
        "\n",
        "!wget -O /content/db/models/sd-1/main/model.safetensors \"{model_link}\"\n",
        "\n",
        "clear_output()\n",
        "print(' [1;32m Model just loaded! ðŸš€')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "BWoTrZLRP5zh",
        "outputId": "100344bd-913c-4504-c5c4-9ae8df7085ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '['ssh-keygen', '-t', 'rsa', '-b', '4096', '-N', '', '-q', '-f', '/content/id_rsa']' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b6fc7553ed36>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mssh_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"id_rsa\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mssh_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mssh_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mgen_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssh_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b6fc7553ed36>\u001b[0m in \u001b[0;36mgen_key\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0marg_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0o600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    527\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ssh-keygen', '-t', 'rsa', '-b', '4096', '-N', '', '-q', '-f', '/content/id_rsa']' returned non-zero exit status 1."
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 3**\n",
        "#@markdown ## Run StableDiffusion InvokeAI\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "clear_output()\n",
        "\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import threading\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def check_and_regenerate_keys():\n",
        "    id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "    id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "\n",
        "    if os.path.exists(id_rsa_file):\n",
        "        os.remove(id_rsa_file)\n",
        "    if os.path.exists(id_rsa_pub_file):\n",
        "        os.remove(id_rsa_pub_file)\n",
        "\n",
        "    gen_key(id_rsa_file)\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "def establish_ssh_tunnel():\n",
        "    key_path = \"/content/InvokeAI/id_rsa\"\n",
        "    tunnel_command = f'ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i {key_path} remote.moe'\n",
        "    !{tunnel_command}\n",
        "\n",
        "def run_invokeai_script():\n",
        "    %cd /content/InvokeAI/\n",
        "    !python /content/InvokeAI/scripts/invokeai-web.py --root /content/db\n",
        "\n",
        "# Check and regenerate keys if they exist\n",
        "check_and_regenerate_keys()\n",
        "\n",
        "# Start SSH tunnel in a separate thread\n",
        "threading.Thread(target=establish_ssh_tunnel, daemon=True).start()\n",
        "\n",
        "# Run InvokeAI script\n",
        "run_invokeai_script()"
      ],
      "metadata": {
        "id": "687CcnSmAob4",
        "outputId": "a9bf3ed7-a498-4820-a607-84c7f50c71c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InvokeAI\n",
            "\u001b[1mhttp\u001b[0m (80)\n",
            "http://flgsvq2kajxcjy5lng2g2no44hxvle6t2czp3nhn35dhx5ny2rwa.remote.moe/\n",
            "\n",
            "$\n",
            " \n",
            "2024-01-31 05:34:11.687378: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-31 05:34:11.687425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-31 05:34:11.688959: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-31 05:34:13.719177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            ">> patchmatch.patch_match: INFO - Compiling and loading c extensions from \"/usr/local/lib/python3.10/dist-packages/patchmatch\".\n",
            ">> patchmatch.patch_match: WARNING - patchmatch failed to load or compile.\n",
            ">> patchmatch.patch_match: WARNING - Refer to https://github.com/invoke-ai/InvokeAI/blob/main/docs/installation/INSTALL_PATCHMATCH.md for installation instructions.\n",
            "\u001b[38;20m[2024-01-31 05:34:21,907]::[InvokeAI]::INFO --> Patchmatch not loaded (nonfatal)\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "\u001b[38;20m[2024-01-31 05:34:23,210]::[uvicorn.error]::INFO --> Started server process [5698]\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,211]::[uvicorn.error]::INFO --> Waiting for application startup.\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,211]::[InvokeAI]::INFO --> InvokeAI version 3.1.0\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,211]::[InvokeAI]::INFO --> Root directory = /content/db\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,350]::[InvokeAI]::INFO --> GPU device = cuda Tesla T4\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,353]::[InvokeAI]::INFO --> Scanning /content/db/models for new models\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,932]::[InvokeAI]::INFO --> Scanned 6 files and directories, imported 0 models\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,940]::[InvokeAI]::INFO --> Model manager service initialized\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,971]::[uvicorn.error]::INFO --> Application startup complete.\u001b[0m\n",
            "\u001b[38;20m[2024-01-31 05:34:23,972]::[uvicorn.error]::INFO --> Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}